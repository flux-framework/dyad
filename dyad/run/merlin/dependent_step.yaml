description:
  description: Merlin handles ensemble of producer and consumer jobs
  name: dependent_step

batch:
  type: flux
  nodes: 2
  queue: pbatch
  #flux_start_opts: -o,-S,log-filename=flux_log-dependent_step.out

env:
  variables:
    SYNC: 1
    ITER: 15

study:
- description: Start
  name: startup
  run:
    cmd: |
      # Clean up the dyad directory
      DYAD_PATH=`$(SPECROOT)/user_apps/args.sh -d -v -s | grep DYAD_PATH | cut -d '=' -f 2`
      pushd `dirname ${DYAD_PATH}` > /dev/null
      rm -rf ${DYAD_PATH} 2> /dev/null
      mkdir -p ${DYAD_PATH} 2> /dev/null
      chmod 775 ${DYAD_PATH}
      popd > /dev/null
      date +"%T.%3N" > $(MERLIN_WORKSPACE)/time.txt
    task_queue: dependent_step
    nodes: 1
    procs: 1
    cores per task: 1

- description: producer
  name: runs-prod
  run:
    cmd: |
      if [  ! -z ${FLUX_PMI_LIBRARY_PATH+x} ]; then
        FPMI2LIB=`dirname ${FLUX_PMI_LIBRARY_PATH}`/libpmi2.so
        if [ -e ${FPMI2LIB} ]; then 
          if [  ! -z ${LD_PRELOAD+x} ]; then
            export LD_PRELOAD=${LD_PRELOAD}:${FPMI2LIB}
          else
            export LD_PRELOAD=${FPMI2LIB}
          fi
        fi
      fi
      hostname >> $(WORKSPACE)/hostname.$(CONTEXT).txt
      export DYAD_ARGS_PARSER_PATH=$(SPECROOT)/user_apps/args.sh
      date +"%T.%3N" >> $(WORKSPACE)/time.$(CONTEXT).txt
      $(LAUNCHER) $(SPECROOT)/user_apps/step_prod.sh \
                  --workspace $(WORKSPACE) --specroot $(SPECROOT) \
                  --sync $(SYNC) --iter $(ITER) --context $(CONTEXT) \
                  --verbose >& $(WORKSPACE)/runs.$(CONTEXT).out
      date +"%T.%3N" >> $(WORKSPACE)/time.$(CONTEXT).txt
    depends: [startup]
    task_queue: dependent_step
    nodes: 1
    procs: 1
    cores per task: 36

- description: consumer
  name: runs-cons
  run:
    cmd: |
      if [  ! -z ${FLUX_PMI_LIBRARY_PATH+x} ]; then
        FPMI2LIB=`dirname ${FLUX_PMI_LIBRARY_PATH}`/libpmi2.so
        if [ -e ${FPMI2LIB} ]; then 
          if [  ! -z ${LD_PRELOAD+x} ]; then
            export LD_PRELOAD=${LD_PRELOAD}:${FPMI2LIB}
          else
            export LD_PRELOAD=${FPMI2LIB}
          fi
        fi
      fi
      hostname >> $(WORKSPACE)/hostname.$(CONTEXT).txt
      export DYAD_ARGS_PARSER_PATH=$(SPECROOT)/user_apps/args.sh
      date +"%T.%3N" >> $(WORKSPACE)/time.$(CONTEXT).txt
      $(LAUNCHER) $(SPECROOT)/user_apps/step_cons.sh \
                  --workspace $(WORKSPACE) --specroot $(SPECROOT) \
                  --sync $(SYNC) --iter $(ITER) --context $(CONTEXT) \
                  --verbose --check >& $(WORKSPACE)/runs.$(CONTEXT).out
      date +"%T.%3N" >> $(WORKSPACE)/time.$(CONTEXT).txt
    depends: [runs-prod]
    task_queue: dependent_step
    nodes: 1
    procs: 1
    cores per task: 36

- description: Dump flux info
  name: flux_info
  run:
    cmd: |
      date +"%T.%3N" >> $(MERLIN_WORKSPACE)/time.txt
      flux kvs dir -R >& $(WORKSPACE)/flux_kvs_dir.out
      flux hwloc info > $(WORKSPACE)/hwlocinfo.txt
    depends: [runs-prod_*, runs-cons_*]
    task_queue: dependent_step

merlin:
  resources:
    task_server: celery
    workers:
      simworkers:
        args: -l INFO --concurrency 2 --prefetch-multiplier 1 -Ofair
        steps: [runs-prod, runs-cons, flux_info]
        nodes: 2
  samples:
    column_labels: [CONTEXT]
    file: $(MERLIN_INFO)/context.csv
    generate:
      cmd: |
        seq 1 1 | awk -v ts=$(MERLIN_TIMESTAMP) \
          '{printf("%s.%s\n", ts, $0)}' > $(MERLIN_INFO)/context.csv
