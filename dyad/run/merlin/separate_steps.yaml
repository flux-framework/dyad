description:
  description: DYAD to support running ensemble jobs of producers and consumers
  name: separate_steps

batch:
  type: flux
  nodes: 2
  queue: pbatch
  #flux_start_opts: -o,-S,log-filename=flux_log-separate_steps.out

env:
  variables:
    SYNC: 0
    ITER: 15
    KVS_NS: prod-cons
    DYAD_INSTALL_PATH: /usr/global/tools/flux/toss_3_x86_64_ib/build/toss_3_x86_64_ib/flux-dyad
    #DYAD_INSTALL_PATH: /usr/global/tools/flux/blueos_3_ppc64le_ib/build/blueos_3_ppc64le_ib/flux-dyad
    DYAD_KVS_DEPTH: 2
    DYAD_KVS_BINS: 256

study:
- description: Start DYAD
  name: startup
  run:
    cmd: |
      export DYAD_ARGS_PARSER_PATH=$(SPECROOT)/user_apps/args.sh
      $(SPECROOT)/dyad/dyad_startup.sh \
                  --workspace $(WORKSPACE) --specroot $(SPECROOT) \
                  --sync $(SYNC) \
                  --mpath $(DYAD_INSTALL_PATH)/src/modules/dyad.so \
                  --verbose >& $(WORKSPACE)/start.out
      flux kvs namespace create $(KVS_NS)
      date +"%T.%3N" > $(MERLIN_WORKSPACE)/time.txt
    task_queue: separate_steps
    nodes: 1
    procs: 1
    cores per task: 1

- description: producer
  name: runs-prod
  run:
    cmd: |
      if [  ! -z ${FLUX_PMI_LIBRARY_PATH+x} ]; then
        FPMI2LIB=`dirname ${FLUX_PMI_LIBRARY_PATH}`/libpmi2.so
        if [ -e ${FPMI2LIB} ]; then 
          if [  ! -z ${LD_PRELOAD+x} ]; then
            export LD_PRELOAD=${LD_PRELOAD}:${FPMI2LIB}
          else
            export LD_PRELOAD=${FPMI2LIB}
          fi
        fi
      fi
      hostname >> $(WORKSPACE)/hostname.$(CONTEXT).txt
      export DYAD_ARGS_PARSER_PATH=$(SPECROOT)/user_apps/args.sh
      date +"%T.%3N" >> $(WORKSPACE)/time.$(CONTEXT).txt
      $(LAUNCHER) $(SPECROOT)/user_apps/step_prod.sh \
                  --workspace $(WORKSPACE) --specroot $(SPECROOT) \
                  --wpath $(DYAD_INSTALL_PATH)/src/wrapper/dyad_wrapper.so \
                  --kvs_namespace $(KVS_NS) --context $(CONTEXT) \
                  --depth $(DYAD_KVS_DEPTH) --bins $(DYAD_KVS_BINS) \
                  --sync $(SYNC) --iter $(ITER) \
                  --verbose >& $(WORKSPACE)/runs.$(CONTEXT).out
      date +"%T.%3N" >> $(WORKSPACE)/time.$(CONTEXT).txt
    depends: [startup]
    task_queue: separate_steps
    nodes: 1
    procs: 1
    cores per task: 36

- description: consumer
  name: runs-cons
  run:
    cmd: |
      if [  ! -z ${FLUX_PMI_LIBRARY_PATH+x} ]; then
        FPMI2LIB=`dirname ${FLUX_PMI_LIBRARY_PATH}`/libpmi2.so
        if [ -e ${FPMI2LIB} ]; then 
          if [  ! -z ${LD_PRELOAD+x} ]; then
            export LD_PRELOAD=${LD_PRELOAD}:${FPMI2LIB}
          else
            export LD_PRELOAD=${FPMI2LIB}
          fi
        fi
      fi
      hostname >> $(WORKSPACE)/hostname.$(CONTEXT).txt
      export DYAD_ARGS_PARSER_PATH=$(SPECROOT)/user_apps/args.sh
      date +"%T.%3N" >> $(WORKSPACE)/time.$(CONTEXT).txt
      $(LAUNCHER) $(SPECROOT)/user_apps/step_cons.sh \
                  --workspace $(WORKSPACE) --specroot $(SPECROOT) \
                  --wpath $(DYAD_INSTALL_PATH)/src/wrapper/dyad_wrapper.so \
                  --kvs_namespace $(KVS_NS) --context $(CONTEXT) \
                  --depth $(DYAD_KVS_DEPTH) --bins $(DYAD_KVS_BINS) \
                  --sync $(SYNC) --iter $(ITER) \
                  --verbose --check >& $(WORKSPACE)/runs.$(CONTEXT).out
      date +"%T.%3N" >> $(WORKSPACE)/time.$(CONTEXT).txt
    depends: [startup]
    task_queue: separate_steps
    nodes: 1
    procs: 1
    cores per task: 36

- description: Dump flux info
  name: flux_info
  run:
    cmd: |
      date +"%T.%3N" >> $(MERLIN_WORKSPACE)/time.txt
      flux kvs dir -R >& $(WORKSPACE)/flux_kvs_dir.out
      flux kvs namespace list > $(WORKSPACE)/flux_kvs_namespace_list.txt
      flux kvs namespace remove $(KVS_NS)
      flux kvs namespace list > $(WORKSPACE)/flux_kvs_namespace_list_cleanup.txt
      flux hwloc info > $(WORKSPACE)/hwlocinfo.txt
    depends: [runs-prod*, runs-cons*]
    task_queue: separate_steps

merlin:
  resources:
    task_server: celery
    workers:
      simworkers:
        args: -l INFO --concurrency 2 --prefetch-multiplier 1 -Ofair
        steps: [runs-prod, runs-cons, flux_info]
        nodes: 2
  samples:
    column_labels: [CONTEXT]
    file: $(MERLIN_INFO)/context.csv
    generate:
      cmd: |
        seq 1 1 > $(MERLIN_INFO)/context.csv
